{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10 (default, Nov 22 2023, 10:22:35) \n",
      "[GCC 9.4.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('datasets/bioview-lizards_TRAIN/run/train/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path = os.path.join(os.getcwd(), 'datasets/bioview-lizards_TRAIN')\n",
    "# yaml_name = 'cuantization.yaml'\n",
    "# yaml_path = os.path.join(train_path, yaml_name)\n",
    "\n",
    "# yaml_content = {\n",
    "#     'train': os.path.join(train_path, \"dataset/train/images\"),\n",
    "#     'val':   os.path.join(train_path, \"dataset/train/images\"),\n",
    "#     'names': {\n",
    "#         0: \"Lizard\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # Crear o modificar el archivo YAML\n",
    "# with open(yaml_path, 'w') as yaml_file:\n",
    "#     yaml.dump(yaml_content, yaml_file, default_flow_style=False)\n",
    "\n",
    "# print(f\"Archivo YAML creado o modificado en '{yaml_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.47 üöÄ Python-3.8.10 torch-2.3.0+cu121 CPU (Intel Xeon Silver 4310 2.10GHz)\n",
      "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'datasets/bioview-lizards_TRAIN/run/train/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (6.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.13.1...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.11M/1.11M [00:00<00:00, 14.4MB/s]\n",
      "Unzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip to /home/qcienmed/mmr689/yolo-consumptions/calibration_image_sample_data_20x128x128x3_float32.npy...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 36.97file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.36...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 1.3s, saved as 'datasets/bioview-lizards_TRAIN/run/train/weights/best.onnx' (11.7 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.17.5...\n",
      "\n",
      "\u001b[07mAutomatic generation of each OP name started\u001b[0m ========================================\n",
      "\u001b[32mAutomatic generation of each OP name complete!\u001b[0m\n",
      "\n",
      "\u001b[07mModel loaded\u001b[0m ========================================================================\n",
      "\n",
      "\u001b[07mModel conversion started\u001b[0m ============================================================\n",
      "\u001b[33mWARNING:\u001b[0m The optimization process for shape estimation is skipped because it contains OPs that cannot be inferred by the standard onnxruntime.\n",
      "\u001b[33mWARNING:\u001b[0m module 'onnx' has no attribute '_serialize'\n",
      "\u001b[07msaved_model output started\u001b[0m ==========================================================\n",
      "\u001b[32msaved_model output complete!\u001b[0m\n",
      "\u001b[32mFloat32 tflite output complete!\u001b[0m\n",
      "\u001b[32mFloat16 tflite output complete!\u001b[0m\n",
      "\u001b[34mInput signature information for quantization\u001b[0m\n",
      "\u001b[34msignature_name\u001b[0m: serving_default\n",
      "\u001b[34minput_name.0\u001b[0m: images \u001b[34mshape\u001b[0m: (1, 640, 640, 3) \u001b[34mdtype\u001b[0m: <dtype: 'float32'>\n",
      "\u001b[32mDynamic Range Quantization tflite output complete!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINT8 Quantization tflite output complete!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFull INT8 Quantization tflite output complete!\u001b[0m\n",
      "\u001b[32mINT8 Quantization with int16 activations tflite output complete!\u001b[0m\n",
      "\u001b[32mFull INT8 Quantization with int16 activations tflite output complete!\u001b[0m\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ‚úÖ 198.2s, saved as 'datasets/bioview-lizards_TRAIN/run/train/weights/best_saved_model' (39.2 MB)\n",
      "\u001b[34m\u001b[1mEdge TPU:\u001b[0m WARNING ‚ö†Ô∏è Edge TPU known bug https://github.com/ultralytics/ultralytics/issues/1185\n",
      "\n",
      "\u001b[34m\u001b[1mEdge TPU:\u001b[0m starting export with Edge TPU compiler 16.0.384591198...\n",
      "\u001b[34m\u001b[1mEdge TPU:\u001b[0m running 'edgetpu_compiler -s -d -k 10 --out_dir \"datasets/bioview-lizards_TRAIN/run/train/weights/best_saved_model\" \"datasets/bioview-lizards_TRAIN/run/train/weights/best_saved_model/best_full_integer_quant.tflite\"'\n",
      "Edge TPU Compiler version 16.0.384591198\n",
      "Searching for valid delegate with step 10\n",
      "Try to compile segment with 255 ops\n",
      "Started a compilation timeout timer of 180 seconds.\n",
      "\n",
      "Model compiled successfully in 2758 ms.\n",
      "\n",
      "Input model: datasets/bioview-lizards_TRAIN/run/train/weights/best_saved_model/best_full_integer_quant.tflite\n",
      "Input size: 3.00MiB\n",
      "Output model: datasets/bioview-lizards_TRAIN/run/train/weights/best_saved_model/best_full_integer_quant_edgetpu.tflite\n",
      "Output size: 3.36MiB\n",
      "On-chip memory used for caching model parameters: 3.00MiB\n",
      "On-chip memory remaining for caching model parameters: 3.87MiB\n",
      "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
      "Number of Edge TPU subgraphs: 1\n",
      "Total number of operations: 255\n",
      "Operation log: datasets/bioview-lizards_TRAIN/run/train/weights/best_saved_model/best_full_integer_quant_edgetpu.log\n",
      "\n",
      "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
      "Number of operations that will run on Edge TPU: 230\n",
      "Number of operations that will run on CPU: 25\n",
      "\n",
      "Operator                       Count      Status\n",
      "\n",
      "CONCATENATION                  1          Operation is otherwise supported, but not mapped due to some unspecified limitation\n",
      "CONCATENATION                  16         Mapped to Edge TPU\n",
      "CONCATENATION                  1          More than one subgraph is not supported\n",
      "SUB                            2          More than one subgraph is not supported\n",
      "STRIDED_SLICE                  2          Operation is otherwise supported, but not mapped due to some unspecified limitation\n",
      "STRIDED_SLICE                  16         Mapped to Edge TPU\n",
      "STRIDED_SLICE                  2          More than one subgraph is not supported\n",
      "MUL                            2          More than one subgraph is not supported\n",
      "MUL                            57         Mapped to Edge TPU\n",
      "ADD                            2          More than one subgraph is not supported\n",
      "ADD                            6          Mapped to Edge TPU\n",
      "MAX_POOL_2D                    3          Mapped to Edge TPU\n",
      "RESHAPE                        2          Operation is otherwise supported, but not mapped due to some unspecified limitation\n",
      "RESHAPE                        1          Mapped to Edge TPU\n",
      "RESHAPE                        3          More than one subgraph is not supported\n",
      "TRANSPOSE                      4          Operation is otherwise supported, but not mapped due to some unspecified limitation\n",
      "TRANSPOSE                      1          Mapped to Edge TPU\n",
      "PAD                            7          Mapped to Edge TPU\n",
      "LOGISTIC                       1          More than one subgraph is not supported\n",
      "LOGISTIC                       57         Mapped to Edge TPU\n",
      "RESIZE_NEAREST_NEIGHBOR        2          Mapped to Edge TPU\n",
      "QUANTIZE                       1          More than one subgraph is not supported\n",
      "QUANTIZE                       1          Mapped to Edge TPU\n",
      "CONV_2D                        1          More than one subgraph is not supported\n",
      "CONV_2D                        63         Mapped to Edge TPU\n",
      "SOFTMAX                        1          More than one subgraph is not supported\n",
      "Compilation child process completed within timeout period.\n",
      "Compilation succeeded! \n",
      "\u001b[34m\u001b[1mEdge TPU:\u001b[0m export success ‚úÖ 3.2s, saved as 'datasets/bioview-lizards_TRAIN/run/train/weights/best_saved_model/best_full_integer_quant_edgetpu.tflite' (3.4 MB)\n",
      "\n",
      "Export complete (203.0s)\n",
      "Results saved to \u001b[1m/home/qcienmed/mmr689/yolo-consumptions/datasets/bioview-lizards_TRAIN/run/train/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=datasets/bioview-lizards_TRAIN/run/train/weights/best_saved_model/best_full_integer_quant_edgetpu.tflite imgsz=640 int8 \n",
      "Validate:        yolo val task=detect model=datasets/bioview-lizards_TRAIN/run/train/weights/best_saved_model/best_full_integer_quant_edgetpu.tflite imgsz=640 data=/home/qcienmed/mmr689/yolo-consumptions/datasets/bioview-lizards_TRAIN/config.yaml int8 \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'datasets/bioview-lizards_TRAIN/run/train/weights/best_saved_model/best_full_integer_quant_edgetpu.tflite'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.export(format='edgetpu',\n",
    "             int8=True\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
